---
title: 01 Algoritmi di Ordinamento
date: 2023-01-15
tags: ASD, algorithm, sorting, complexity
difficulty: üü¢
---

<h1  style="text-align: center;">  01 Algoritmi di Ordinamento </h1> 
Gli algoritmi di ordinamento, sono algoritmi che hanno lo **scopo di ordinare un insieme di elementi** in:
- ordine cronologico
- di dimensioni
- di nome
- ...

Esistono diversi algoritmi per questo scopo:


# Bubble Sort

Il bubble sort √® l'algoritmo di ordinamento pi√π semplice, esso confronta ogni coppia di elementi adiacenti e li scambia se non sono in ordine, il processo viene ripetuto fin quando non ci sono pi√π scambi necessari (gli elementi sono in ordine)

Un esempi di codice che mette in ordine crescente di grandezza in C:
```c
void bubble_sort(int arr[], int n) {
    int tmp;
    int i, j;
    
    for (i = 0; i < n-1; i++) {
        for (j = 0; j < n-i-1; j++) {
            if (arr[j] > arr[j+1]) {
                tmp = arr[j];
                arr[j] = arr[j+1];
                arr[j+1] = tmp;
            }
        }
    }
}
```

Vengono utilizzati due cicli `for` per scorrere attraverso gli elementi del array. 
- Il primo ciclo  **scorre** attraverso gli elementi del array **dalla prima alla penultima posizione**.
- il secondo ciclo **scorre** attraverso gli elementi **dalla prima alla posizione corrente del primo ciclo meno uno**, se l'elemento corrente **(`arr[j]`) √® maggiore** dell'elemento successivo **(`arr[j+1]`),** allora **gli elementi vengono scambiati** utilizzando la variabile `tmp`.

L'algoritmo √® molto lento, il tempo di esecuzione infatti √®:

| **Best Case** | **Average Case** | **Worst Case** |
| ------------- | ---------------- | -------------- |
| $O(n^{2})$    | $O(n^{2})$       | $O(n^{2})$     |


# Selection Sort

Il selection sort seleziona cerca e seleziona l'elemento pi√π piccolo e lo scambia con il primo elemento non in ordine, il processo si ripete fin quando tutti gli elementi non sono in ordine.

Un esempio di codice in C:
```c
void selection_sort(int arr[], int n) {
    int i, j, min_idx;
    for (i = 0; i < n-1; i++) {
        min_idx = i;
        for (j = i+1; j < n; j++) {
            if (arr[j] < arr[min_idx]) {
                min_idx = j;
            }
        }
        int temp = arr[min_idx];
        arr[min_idx] = arr[i];
        arr[i] = temp;
    }
}
```

Utilizziamo due cicli for per scorrere attraverso gli elementi del vettore. 
- Il primo ciclo scorre attraverso gli elementi del vettore dalla prima alla penultima posizione.
- il secondo ciclo  scorre attraverso gli elementi **dalla posizione successiva alla posizione corrente del primo ciclo all'ultima posizione**,  si confronta l'elemento corrente (`arr[j]`) con l'elemento in posizione `min_idx`, se l'elemento corrente √® minore allora si aggiorna `min_idx` con la posizione corrente.
- **Alla fine dei due cicli si effettua lo scambio** tra l'elemento in posizione `min_idx` e l'elemento nella posizione i-esima del primo ciclo.

Anche in questo caso l'algoritmo √® abbastanza lento, ma siccome effettua meno scambi del bubble sort √® leggermente pi√π veloce di quest'ultimo:

| **Best Case** | **Average Case** | **Worst Case** |
| ------------- | ---------------- | -------------- |
| $O(n^{2})$    | $O(n^{2})$       | $O(n^{2})$     |


# Insertion Sort

Nell'Insertion Sort viene preso un elemento gi√† in ordine e da quello si spostano gli altri elementi uno alla volta nella posizione corretta.

```c
void insertion_sort(int arr[], int n) {
    int i, key, j;
    for (i = 1; i < n; i++) {
        key = arr[i];
        j = i-1;
        while (j >= 0 && arr[j] > key) {
            arr[j + 1] = arr[j];
            j = j - 1;
        }
        arr[j + 1] = key;
    }
}
```

Utilizza due cicli `for` per scorrere attraverso gli elementi del vettore. 
- Il primo ciclo (i) scorre attraverso gli elementi del vettore dalla seconda all'ultima posizione.
- il secondo ciclo while scorre attraverso gli elementi dalla posizione corrente del primo ciclo fino alla posizione 0, si confronta l'elemento corrente (`arr[j]`) con l'elemento `key` (`arr[i]`) **se l'elemento corrente √® maggiore allora si sposta l'elemento corrente una posizione avanti e si continua a comparare con l'elemento precedente**. 
- Alla fine del secondo ciclo si inserisce l'elemento `key` nella posizione corretta.

E' un **algoritmo stabile e in-place** e quindi adatto per la gestione di grandi set di dati

> [!abstract] Algoritmo In-Place
> Un algoritmo si dice In-Place quando va ad utilizzare la stessa memoria per ordinare dei dati che utilizza, quindi risulter√† meno pesante per la memoria.

La complessit√† dell'insertion sort cambia in base a se il nostro insieme di elementi √® gi√† parzialmente ordinato o meno:

| **Best Case** | **Average Case** | **Worst Case** |
| ------------- | ---------------- | -------------- |
| $O(n)$    | $O(n)$       | $O(n^{2})$     |


# Merge Sort

Il merge sort √® un algoritmo di tipo **divide et impera**, ovvero divide un set di elementi a met√† ordinando le due met√† con altri algoritmi di ordinamento e riunendo le due met√† ordinate

```c
void merge(int arr[], int l, int m, int r) {
    int i, j, k;
    int n1 = m - l + 1;
    int n2 = r - m;
    int L[n1], R[n2];
    
    for (i = 0; i < n1; i++) {
        L[i] = arr[l + i];
    }
    for (j = 0; j < n2; j++) {
        R[j] = arr[m + 1+ j];
    }
    
    i = 0;
    j = 0;
    k = l;
    while (i < n1 && j < n2) {
        if (L[i] <= R[j]) {
            arr[k] = L[i];
            i++;
        } else {
            arr[k] = R[j];
            j++;
        }
        k++;
    }
    
    while (i < n1) {
        arr[k] = L[i];
        i++;
        k++;
    }
    while (j < n2) {
        arr[k] = R[j];
        j++;
        k++;
    }
}

void merge_sort(int arr[], int l, int r) {
    if (l < r) {
        int m = l+(r-l)/2;
        merge_sort(arr, l, m);
        merge_sort(arr, m+1, r);
        merge(arr, l, m, r);
    }
}
```

Il codice utilizza due funzioni: 
-  `merge()` prende come input tre indici (`l, m, r`) e un array, **fa una copia degli elementi nell'array in due array temporanei** `L` e `R` e li combina in ordine nel array originale.
- `merge_sort()`, funzione principale, utilizza un approccio ricorsivo per dividere l'array in sotto-array fino a quando ogni sotto-array contiene solo un elemento. Quindi, utilizza la funzione `merge()` per **combinare gli array ordinati in un unico array ordinato**


![[Merge-sort-example.gif|center|500]]


√à un algoritmo **non in-place**, **stabile** e adatto a **grandi set di dati**, la sua complessit√† √®:

| **Best Case** | **Average Case** | **Worst Case** |
| ------------- | ---------------- | -------------- |
| $O(n)$    | $O(n\log(n))$       | $O(n\log(n))$     |

## Best Case

Si ricade nel caso migliore quando il data set √® gi√† ordinato in quanto non bisogna eseguire swap.

## Worst Case

Si ricade nel caso peggiore quando gli elementi 


# Quick Sort

Quick sort √® un altro algoritmo "divide et impera", esso funziona scegliendo un elemento **pivot** dalla serie di elementi da ordinare e quindi **separando gli elementi in base al loro valore rispetto al pivot**. 
Gli **elementi minori** del pivot vengono **posizionati a sinistra** e **quelli maggiori a destra** del pivot. 
Quindi si ripete il processo di ordinamento per entrambe le met√† (ricorsivamente) finch√© l'intero array non √® ordinato.

Un esempio di codice in C:
```c
int partition (int arr[], int low, int high) {
    int pivot = arr[high];
    int i = (low - 1);
    int j;
    
    for (j = low; j <= high- 1; j++) {
        if (arr[j] <= pivot) {
            i++;
            int temp = arr[i];
            arr[i] = arr[j];
            arr[j] = temp;
        }
    }
    
    int temp = arr[i + 1];
    arr[i + 1] = arr[high];
    arr[high] = temp;
    return (i + 1);
}

void quick_sort(int arr[], int low, int high) {
    if (low < high) {
        int pi = partition(arr, low, high);
        quick_sort(arr, low, pi - 1);
        quick_sort(arr, pi + 1, high);
    }
}
```

Anche qui abbiamo due funzioni: 
- `partition()` ha tre parametri `low, high` e un array, **sceglie un pivot**, **scambia gli elementi minori del pivot con quelli maggiori del pivot** e **restituisce la posizione del pivot**.
-  `quick_sort()`  utilizza un approccio ricorsivo per dividere l'array in sotto-array fino a quando ogni sotto-array contiene solo un elemento.

![[quick_sort_partition_animation.gif|center]]


La scelta del pivot solitamente √®:
- Il **primo elemento**
- l'**ultimo elemento**
- **elemento** **mediano**
- un **elemento random**

Il quick sort √® un algoritmo **in-place**, **non stabile** (per via della scelta random del pivot) e adatto a **grandi set di dati**, la complessit√† √®:

| **Best Case** | **Average Case** | **Worst Case** |
| ------------- | ---------------- | -------------- |
| $O(n\log(n))$    | $O(n\log(n))$       | $O(n^{2})$     |

## Best Case

Quando le  **partizioni** sono di dimensioni **equivalenti**.

## Worst Case

Quando il **pivot** √® l**'elemento pi√π grande o pi√π piccolo** del data set.


# | [[02. Liste e Array Dinamici| Next ‚Üí]]


# Flashcards

Qual √® la complessit√† del Bubble Sort nel **Best Case**:: $O(n^{2})$

Qual √® la complessit√† del Bubble Sort nel **Average Case**:: $O(n^{2})$

Qual √® la complessit√† del Bubble Sort nel **Worst Case**:: $O(n^{2})$

Qual √® la complessit√† del Selection Sort nel **Best Case**:: $O(n^{2})$

Qual √® la complessit√† del Selection Sort nel **Average Case**:: $O(n^{2})$

Qual √® la complessit√† del Selection Sort nel **Worst Case**:: $O(n^{2})$

Qual √® la complessit√† del Insertion Sort nel **Best Case**:: $O(n)$

Qual √® la complessit√† del Insertion Sort nel **Average Case**:: $O(n)$

Qual √® la complessit√† del Insertion Sort nel **Worst Case**:: $O(n^{2})$

Qual √® la complessit√† del Merge Sort nel **Best Case**:: $O(n)$

Qual √® la complessit√† del Merge Sort nel **Average Case**:: $O(n\log(n))$

Qual √® la complessit√† del Merge Sort nel **Worst Case**:: $O(n\log(n))$

Qual √® la complessit√† del Quick Sort nel **Best Case**:: $O(n\log(n))$

Qual √® la complessit√† del Quick Sort nel **Average Case**:: $O(n\log(n))$

Qual √® la complessit√† del Quick Sort nel **Worst Case**:: $O(n^{2})$

In base a cosa l'**insertion sort** ha una complessit√† minore:: Se il set di elementi √® **gi√† parzialmente (o completamente) ordinato**

Cos'√® un algoritmo **in-place**:: Un algoritmo che utilizza lo la stessa quantit√† di memoria dei dati stessi che andr√† a utilizzare.

Cosa comporta avere un algoritmo **stabile** e **in-place**:: Permette di lavorare su grandi quantit√† di dati.

Algoritmi in Place
?
- **Bubble Sort**
- **Selection Sort**
- **Insertion Sort**

Come viene scelto il **pivot** nel Quick Sort
?
- Il **primo elemento**
- l'**ultimo elemento**
- **elemento mediano**
- un **elemento random**

Uno dei motivi per il quale il **Quick Sort** non √® stabile:: La **scelta randomica** del pivot.