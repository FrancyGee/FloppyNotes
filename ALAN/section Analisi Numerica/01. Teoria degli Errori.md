---
title: Teoria degli errori  
date: 2023-01-13
tags: ALAN, error
difficulty: 🟠
---

<h1  style="text-align: center;"> 01. Teoria degli errori ⚠️</h1>

# Dal problema matematico al mondo reale 

La matematica ha molteplici applicazioni per risolvere problemi nel mondo reale si pensi finanza, alla medicina, la costruzione di veicoli ecc...
Per applicare la matematica a questi cambi è necessario che il modello che andiamo ad utilizzare abbia le seguenti proprietà: 
- *coerente*.
- *una soluzione esistente* (preferibilmente unica).
- *proprietà qualitative.*

![[Pasted image 20221001224643.png|300|center]]


## Dalla matematica al Computer

La branca della matematica che si occupa dei problemi informatici è la **matematica computazionale** che è trasversale all'algebra, la geometria e l'analisi.
L'**analisi numerica** interseca quella che è la *matematica computazionale* con altri settori della matematica per trovare soluzioni nel mondo dell'informatica.

Dal mondo reale otteniamo un **numero finito di input** con i quali va creato un **modello matematico** che dovrà successivamente essere **discretizzato** per poter creare un **modello comprensibile per il nostro computer** che restituirà un numero **finito di output**.

L'output ottenuto con il calcolatore potrebbe però essere differente dall'output teorico che otteniamo con la matematica, questo per due motivi principali:
- *La difficoltà del calcolatore a rappresentare i numeri reali a causa della memoria limitata.*
- *L'approssimazione delle operazioni aritmetiche*.

I limiti di un calcolatore obbligano quindi allo studio degli errori, lo loro propagazione, la previsione, l'analisi e nel caso la riduzione di esso.


![[ALAN-input_output_problema.excalidraw|center|600]]


## Come funziona l'Analisi Numerica

A differenza di altri modelli l'analisi numerica risolve i problemi utilizzando i numeri $\mathbb{R}$ oltre allo zero che rispettano questa regola:
$$
\boxed{\pm 0.c_{1}c_{2}c_{3}\ldots c_{n} \times B^{e}, \quad c_{1}\not= 0}
$$
Ovvero che tutti i numeri $\mathbb{R}$ oltre allo zero devono essere **rappresentati** nella **base assegnata** $B$ con un finito numero $n$ di **cifre** $c_x$ e con un **esponente** $e$, esempio:
$$
0.12345  \times 10^{5}
$$
Dove $12345$ è il numero da rappresentare, $B = 10, n=10, e=5$, questa rappresentazione si chiama **floating point**, il tutto viene approfondito qui: [[02.Rappresentazione dei numeri]]


#  Tipi di Errore

Il passaggio da `Mondo reale->Mondo Matematica->Calcolatore` contiene tre tipi di errori:
- **Errore analitico**.
- **Errore inerente**.
- **Errori algoritmici**.

Su questi errori le misure possibili sono due:
- ***errore assoluto*** che è la differenza tra il valore ottenuto e il valore atteso: $\delta x = x_{p}-x$
- ***errore relativo*** che è: $x_{p}=x(1+\epsilon) \quad x \not = 0$

## Errore analitico

L'errore analitico è avviene nel passaggio in cui dal *problema reale* traduciamo in *modello matematico* o *discretiziamo*.

## Errore Inerenti

Sono errori che riguardano la **misurazione dei dati (gli input e output** ).
Nell'informatica l'errore avviene quando **cerchiamo di rappresentare un numero $\mathbb{R}$ con un numero finito di cifre**, in quanto per rappresentare un numero su un calcolatore è necessario approssimare il numero (*questo è il motivo per il quale è impossibile per un computer rappresentare numeri con cifre illimitate*).

La "non correttezza" della rappresentazione influisce sia sugli input che sugli output di un algoritmo, infatti un input non corretto può propagare l'errore della rappresentazione fino all'output.


### Calcolare l'Errore Inerente

Consideriamo un algoritmo $f : \mathbb{R} \to \mathbb{R}$ che ha $x$ come input e $y$ come output, se $x$ e perturbato ($x_p$ o $\tilde x$)  diciamo che:
- $\epsilon_{x}$ è l'errore sull'input.
- $\epsilon_{y}$ è l'errore dell'output.
Allora per calcolare $\epsilon_x$ avremo:
$$
\epsilon_x = \dfrac{(x_{p}-x)}{x}
$$
Mentre per calcolare $\epsilon_{y}$ avremo:
$$
\epsilon_{y}= \dfrac{|f(x_{p}) - f(x)|}{|f(x)|}
$$
Se otteniamo che $\epsilon_{y}>>\epsilon_{x}$ ( leggasi *molto maggiore di* ) allora abbiamo **un mal condizionamento** e avremo che **piccole perturbazioni sull'input andranno a creare grandi perturbazioni sull'output**.

> [!INFO] **PERTURBAZIONE**
> Perturbato significa **affetto da errore inerente**


### Condizionamento

Abbiamo parlato di *condizionamento, esso è il **rapporto tra l'errore commesso sul risultato di un calcolo e l'incertezza sui dati in ingresso** e lo scriviamo come:
$$
c = \frac{xf^{'}(x)}{f(x)} \cdot \frac{x}{x_p-x}
$$

In base al rapporto possiamo definire il condizionamento di un problema:
- Se il **rapporto è basso**, il problema è *ben condizionato.*
- Se il **rapporto è alto**, il problema è *mal condizionato*.

$$
cond := \frac{\epsilon_{x}}{\epsilon_{y}} \quad \approx \quad \lim_{x_{p}\to x}cond =cf:=x \frac{f^{'}(x)}{f(x)} 
$$

### esempio

Un esempio pratico, prendiamo:
$$
\begin{cases}
x + y = 2  \\
1001x + 1000y = 2001
\end{cases}
$$
Abbiamo che l'input del problema è formato dalla matrice:
$$
\begin{pmatrix}
1 & 1  \\ 1001 & 1000
\end{pmatrix}
$$
E come output abbiamo:
$$
\begin{pmatrix}
2  \\ 2001
\end{pmatrix}
$$
Ora se noi avessimo una perturbazione di $\frac{1}{100}$ (perturbazione del $1\%$) sull'input, quindi $\epsilon_{x}= \frac{1}{100}$ , avremo che:
$$
\begin{cases}
\left(1 + \dfrac{1}{100}\right)x + y = 2  \\
1001x + 1000y = 2001
\end{cases}
$$
Ovvero che:
$$
\tilde x = x_{p}= x(1+\epsilon_{x})=\left(1 + \frac{1}{100}\right) = -\frac{1}{9}
$$
e:
$$
\tilde y = y_{p} = \frac{1901}{900}
$$

### Coefficiente di Amplificazione 

Il **coefficiente di amplificazione** ($cf$) è il rapporto tra il prodotto di $x$ e la derivata di $f(x)$
per $f(x)$ scritto:
$$
cf = \frac{xf'(x)}{f(x)}
$$
Quindi scriviamo che il *condizionamento* è uguale a:
$$
c = \frac{x cf}{x_{p} - x}
$$
### esempio

Prendiamo la funzione $f(x) = 1 - \cos  x \Rightarrow f^{'}(x) = \sin x$ avremo che:
$$
cf = \dfrac{x\sin x}{1-\cos x}
$$

il caso che andremo a studiare sarà:
$$
\cos(z) \approx 1 \leftrightarrow x \approx 0
$$
Quindi avremo da studiare il limite per:
$$
\lim_{x \to 0} cf = \lim_{x\to 0} \frac{x \sin x}{1 - \cos x} = \lim_{x\to 0} \frac{x \sin x(1+\cos x)}{1 - \cos x} = 2
$$
Avremo quindi un errore di $2\epsilon$.

## Errore Algoritmico

L'*errore algoritmico* riguarda le approssimazioni che effettuiamo sull'algoritmo utilizzato, ovvero sui **risultati intermedi**.

Per poter analizzare un algoritmo dobbiamo utilizzare le seguenti formule:
$$
\epsilon_{a\pm b}= \frac{a}{a\pm b}\epsilon_{a}\frac{b}{a\pm b}\epsilon_{b}+\epsilon,
$$
$$
\epsilon_{ab} = \epsilon_{a} + \epsilon_{b} + \epsilon,   
$$
$$
\epsilon_{\frac{a}{b}} = \epsilon_{a} - \epsilon_{b} + \epsilon,   
$$

## Analisi in Avanti

### esempio:
$$f(x) = x^{2} - 7x = x(x-7)$$
Sappiamo che l'**errore inerente** in questi due algoritmi
1. $\epsilon_{in} \approx cf\epsilon_{x}$  
2. $cf = \frac{2x-7}{x-7}$

Abbiamo che l'algoritmo 1 si calcola con:
- $q = x\cdot x$ ($\epsilon_{q}$)
- $p = 7 \cdot x$ ($\epsilon_p$)
- $y1 = p - q$ ($\epsilon_{y1}$)

E l'algoritmo 2 si calcola con:
- $d = x - 7$ ($\epsilon_d$)
- $y2 = x \cdot d$ ($\epsilon_{y2}$)

Vediamo come si *propaga l'errore in questi due algoritmi esempi* $|\epsilon_{\square}| \le u$.

Vediamo che analizzando il primo algoritmo abbiamo che:
$$
\begin{aligned}
\epsilon_{q}= \epsilon_{q}\\
\epsilon_{p}= \epsilon_{p}\\
\end{aligned}
$$
E che quindi l'errore totale è:
$$
\epsilon_{alg1} = \frac{q}{y1}\epsilon_{p}-\frac{q}{y1}\epsilon_{y1} = \frac{x^{2}}{x^{2}-7x}\epsilon_q-\frac{7x}{x^{2}-7x}\epsilon_{p}+ \epsilon_{y1}
$$
Consideriamo $x \approx 7$ altrimenti ($\epsilon_{alg1}$ basso), mentre se volgiamo sapere quando $x=7$ dobbiamo fare il limite:
$$
\lim_{x\to 7}\frac{7}{x-7}=\pm\infty
$$

Vediamo che analizzando il secondo algoritmo abbiamo che:
$$
\epsilon_{alg2}= \epsilon_{x}+\epsilon_{d}+\epsilon_{y2} = \epsilon_{d}+\epsilon_{y2} \Rightarrow | \epsilon_{alg2}| \le 2u
$$
> [!NOTE] NOTA
>Ogni volta che l'errore algoritmico ha un ordine di grandezza paragonabile all'errore inerente (come nel primo algoritmo) si dice **Algoritmo Stabile**



# | [[02.Rappresentazione dei numeri| Next →]]





# Flashcards
